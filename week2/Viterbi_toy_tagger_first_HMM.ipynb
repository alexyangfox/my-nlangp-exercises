{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Toy Viterbi Tagger (First Order Markov Assumption)\n",
    "\n",
    "在这个练习里面，我需要用 Viterbi 算法来实现一个 toy POS tagger.  \n",
    "在这个 toy tagger 里面：  \n",
    "\n",
    "- tag 的类型一共只有 3 种： `NN` , `VV` 和 `IN`, 分别表示的是名词、动词和介词   \n",
    "- tagger 使用`first order markov assumption`, 这意味着 `transistion probability` 的形式为 `p(s|u)`, 而不是 `Micheal` 课程里面的 `p(s|u,v)`   \n",
    "- `transistion probabilities` 和 `emission probabilities` 都是已知的  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case \n",
    "\n",
    "- `mary lives in chengdu` 中的每一个词语分别应该被 Tag 成为： `NN VV IN NN`  \n",
    "\n",
    "这里列出所有的 `transistion probability` 和 `emission probability`。  \n",
    "\n",
    "在我们的 test case 里面，只有 3 种 tags (如果算上 `STOP` 就是 4 种)， 于是 `transistion probabilities` $q(s|u)$ 有以下这些情况：   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_p=dict();\n",
    "\n",
    "# 句子开始的第一个 Tag 为 NN，VV或者IN 的概率 \n",
    "trans_p['NN|*'] = 0.5; \n",
    "trans_p['VV|*'] = 0.1;\n",
    "trans_p['IN|*'] = 0.4; \n",
    "\n",
    "# 然后是 9 种： p(s|u)  , s 和 u 各有 3 种可能 \n",
    "trans_p['NN|NN'] = 0.2;\n",
    "trans_p['VV|NN'] = 0.5;\n",
    "trans_p['IN|NN'] = 0.3;\n",
    "\n",
    "trans_p['NN|IN'] = 0.9;\n",
    "trans_p['VV|IN'] = 0.05;\n",
    "trans_p['IN|IN'] = 0.05;\n",
    "\n",
    "trans_p['NN|VV'] = 0.5;\n",
    "trans_p['VV|VV'] = 0.05;\n",
    "trans_p['IN|VV'] = 0.45;\n",
    "\n",
    "# 句子最后一个单词的 tag \n",
    "trans_p['STOP|NN'] = 0.8;\n",
    "trans_p['STOP|VV'] = 0.15;\n",
    "trans_p['STOP|IN'] = 0.05;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是 `emission probabilities` $e(x|s)$， 我们只考虑上面句子里的 4 个单词，然后这里有 4 种 tag ，于是 :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emiss_p= dict();\n",
    " \n",
    "emiss_p['mary|NN'] =  0.45\n",
    "emiss_p['lives|NN']  =  0.05\n",
    "emiss_p['in|NN'] = 0.05 \n",
    "emiss_p['chengdu|NN'] =  0.45\n",
    "\n",
    "\n",
    "emiss_p['mary|IN'] =  0.05\n",
    "emiss_p['lives|IN']  =  0.05\n",
    "emiss_p['in|IN'] = 0.85 \n",
    "emiss_p['chengdu|IN'] =  0.05\n",
    "\n",
    "\n",
    "emiss_p['mary|VV'] =  0.05\n",
    "emiss_p['lives|VV']  =  0.85\n",
    "emiss_p['in|VV'] = 0.05 \n",
    "emiss_p['chengdu|VV'] =  0.05\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么，接下来的练习里面，我们应该能做出一个 tagger， 能够准确地 tag 出 `mary lives in chengdu` 这句话里的 `POS`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the generative model \n",
    "\n",
    "先来回忆一下这里的 `generative model`:  \n",
    "\n",
    "$ p(x_1...x_n,y_1...y_{n+1}) = \\prod_{i=1}^{n+1}q(y_i|y_{i-1})) \\prod_{i=1}^{n}e(x_i|y_i) $   \n",
    "\n",
    "其中 $y_n$ 是 `tag`, 而 $x_n$ 是 `word`.  \n",
    "另外要注意的是 $y_{n+1} = STOP$ \n",
    "\n",
    "我们已经知道的 $x_1...x_n$, 需要找到一个 $y_1...y_{n+1}$ 让 $ p(x_1...x_n,y_1...y_{n+1})$ 的值是最大的。 \n",
    "\n",
    "## Brute force way \n",
    "\n",
    "因为我们这里的句子很短， tags 的种类也很少，我们可以先试着用 `brute force way` 来看看。  \n",
    "我们可以列举出所有的可能： 一共4个单词，每一个单词的 tag 有 3 种可能，于是一共是 81 种可能。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag Sequence of \"NN VV IN NN\" has the maximum probability of 0.011850806250000002\n"
     ]
    }
   ],
   "source": [
    "all_possible_tagged_seqs = dict()\n",
    "\n",
    "all_possible_tags = ['VV','NN','IN']\n",
    "\n",
    "# FIXME: any other better way than 4 loops ?\n",
    "\n",
    "for tag_of_mary in all_possible_tags:\n",
    "    for tag_of_lives in all_possible_tags:\n",
    "        for tag_of_in in all_possible_tags:\n",
    "            for tag_of_chengdu in all_possible_tags:\n",
    "                all_possible_tagged_seqs[tag_of_mary+' '+ tag_of_lives + ' ' + tag_of_in + ' ' + tag_of_chengdu] = (\n",
    "                    trans_p[tag_of_mary+'|*'] * trans_p[tag_of_lives+'|' + tag_of_mary] *\n",
    "                    trans_p[tag_of_in+'|'+tag_of_lives] * trans_p[tag_of_chengdu+'|'+tag_of_in] *  \n",
    "                    trans_p['STOP|'+tag_of_chengdu] \n",
    "                    * emiss_p['mary|'+tag_of_mary] * emiss_p['lives|'+tag_of_lives] * \n",
    "                    emiss_p['in|'+tag_of_in] * emiss_p['chengdu|'+tag_of_chengdu] )\n",
    "\n",
    "tagged_seq_with_max_prob = ''\n",
    "max_prob = 0\n",
    "\n",
    "for k,v in all_possible_tagged_seqs.items():\n",
    "    if v > max_prob:\n",
    "        max_prob = v \n",
    "        tagged_seq_with_max_prob = k\n",
    "        \n",
    "print('Tag Sequence of \"'+ tagged_seq_with_max_prob + '\" has the maximum probability of ' + str(max_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Viterbi Way \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = dict() \n",
    "\n",
    "# max_prob_to_this_node : 到这个 node 的各种 path 中， 概率最大值 \n",
    "# pre_node : 到这个 node 的各种 path 中，概率最大的那个path 里，上一个 node 是什么 \n",
    "nodes['*'] = {'max_prob_to_this_node':1, 'pre_node':'NOTHING'}\n",
    "\n",
    "# 下面来考察和 'mary' 相关的 nodes\n",
    "nodes['mary,NN'] = { 'max_prob_to_this_node': nodes['*']['max_prob_to_this_node'] \n",
    "                    * trans_p['NN|*'] * emiss_p['mary|NN'], \n",
    "                    'pre_node': '*'}\n",
    "\n",
    "nodes['mary,VV'] = { 'max_prob_to_this_node': nodes['*']['max_prob_to_this_node'] \n",
    "                    * trans_p['VV|*'] * emiss_p['mary|VV'], \n",
    "                    'pre_node': '*'}\n",
    "\n",
    "nodes['mary,IN'] = { 'max_prob_to_this_node': nodes['*']['max_prob_to_this_node'] \n",
    "                    * trans_p['IN|*'] * emiss_p['mary|IN'], \n",
    "                    'pre_node': '*'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
